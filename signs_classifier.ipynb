{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import PyInstaller\n",
    "from PyInstaller.utils.hooks import collect_submodules\n",
    "hiddenimports = collect_submodules('tensorflow_core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-9-d23fc3db0080>\", line 2, in <module>\n",
      "    from tensorflow import tensorflow_core\n",
      "ImportError: cannot import name 'tensorflow_core' from 'tensorflow' (D:\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2034, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\Anaconda\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\Anaconda\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\Anaconda\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"D:\\Anaconda\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"D:\\Anaconda\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 43, in <module>\n",
      "    from . _api.v2 import autodiff\n",
      "ImportError: cannot import name 'autodiff' from 'tensorflow_core._api.v2' (D:\\Anaconda\\lib\\site-packages\\tensorflow_core\\_api\\v2\\__init__.py)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'tensorflow_core' from 'tensorflow' (D:\\Anaconda\\lib\\site-packages\\tensorflow\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import tensorflow_core\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow_core.keras.layers import BatchNormalization\n",
    "from tensorflow_core.keras.layers import Conv2D\n",
    "from tensorflow_core.keras.layers import MaxPooling2D\n",
    "from tensorflow_core.keras.layers import Activation\n",
    "from tensorflow_core.keras.layers import Flatten\n",
    "from tensorflow_core.keras.layers import Dropout\n",
    "from tensorflow_core.keras.layers import Dense\n",
    "from tensorflow_core.keras.utils import to_categorical\n",
    "from tensorflow_core.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow_core.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = r\"D:\\users\\new owner\\Desktop\\TKS\\Christmas Break\\gtsrb-german-traffic-sign\"\n",
    "img_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset):\n",
    "    rows = pd.read_csv(dataset)\n",
    "    rows = rows.sample(frac=1).reset_index(drop=True)\n",
    "    images = []\n",
    "    classes = []\n",
    "    for i, row in rows.iterrows():\n",
    "        img_class = row[\"ClassId\"]\n",
    "        img_path = row[\"Path\"]\n",
    "\n",
    "        image = os.path.join(data, img_path)\n",
    "\n",
    "        image = cv2.imread(image)\n",
    "        image_rs = cv2.resize(image, (img_size, img_size), 3)\n",
    "\n",
    "        R, G, B = cv2.split(image_rs)\n",
    "\n",
    "        img_r = cv2.equalizeHist(R)\n",
    "        img_g = cv2.equalizeHist(G)\n",
    "        img_b = cv2.equalizeHist(B)\n",
    "\n",
    "        new_image = cv2.merge((img_r, img_g, img_b))\n",
    "\n",
    "        images.append(new_image)\n",
    "        classes.append(img_class)\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(f\"loaded: {i}\")\n",
    "\n",
    "    X = np.array(images)\n",
    "    y = np.array(classes)\n",
    "    \n",
    "    return(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = r\"D:\\users\\new owner\\Desktop\\TKS\\Christmas Break\\gtsrb-german-traffic-sign\\Train.csv\"\n",
    "test_data = r\"D:\\users\\new owner\\Desktop\\TKS\\Christmas Break\\gtsrb-german-traffic-sign\\Test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded: 0\n",
      "loaded: 500\n",
      "loaded: 1000\n",
      "loaded: 1500\n",
      "loaded: 2000\n",
      "loaded: 2500\n",
      "loaded: 3000\n",
      "loaded: 3500\n",
      "loaded: 4000\n",
      "loaded: 4500\n",
      "loaded: 5000\n",
      "loaded: 5500\n",
      "loaded: 6000\n",
      "loaded: 6500\n",
      "loaded: 7000\n",
      "loaded: 7500\n",
      "loaded: 8000\n",
      "loaded: 8500\n",
      "loaded: 9000\n",
      "loaded: 9500\n",
      "loaded: 10000\n",
      "loaded: 10500\n",
      "loaded: 11000\n",
      "loaded: 11500\n",
      "loaded: 12000\n",
      "loaded: 12500\n",
      "loaded: 13000\n",
      "loaded: 13500\n",
      "loaded: 14000\n",
      "loaded: 14500\n",
      "loaded: 15000\n",
      "loaded: 15500\n",
      "loaded: 16000\n",
      "loaded: 16500\n",
      "loaded: 17000\n",
      "loaded: 17500\n",
      "loaded: 18000\n",
      "loaded: 18500\n",
      "loaded: 19000\n",
      "loaded: 19500\n",
      "loaded: 20000\n",
      "loaded: 20500\n",
      "loaded: 21000\n",
      "loaded: 21500\n",
      "loaded: 22000\n",
      "loaded: 22500\n",
      "loaded: 23000\n",
      "loaded: 23500\n",
      "loaded: 24000\n",
      "loaded: 24500\n",
      "loaded: 25000\n",
      "loaded: 25500\n",
      "loaded: 26000\n",
      "loaded: 26500\n",
      "loaded: 27000\n",
      "loaded: 27500\n",
      "loaded: 28000\n",
      "loaded: 28500\n",
      "loaded: 29000\n",
      "loaded: 29500\n",
      "loaded: 30000\n",
      "loaded: 30500\n",
      "loaded: 31000\n",
      "loaded: 31500\n",
      "loaded: 32000\n",
      "loaded: 32500\n",
      "loaded: 33000\n",
      "loaded: 33500\n",
      "loaded: 34000\n",
      "loaded: 34500\n",
      "loaded: 35000\n",
      "loaded: 35500\n",
      "loaded: 36000\n",
      "loaded: 36500\n",
      "loaded: 37000\n",
      "loaded: 37500\n",
      "loaded: 38000\n",
      "loaded: 38500\n",
      "loaded: 39000\n",
      "loaded: 0\n",
      "loaded: 500\n",
      "loaded: 1000\n",
      "loaded: 1500\n",
      "loaded: 2000\n",
      "loaded: 2500\n",
      "loaded: 3000\n",
      "loaded: 3500\n",
      "loaded: 4000\n",
      "loaded: 4500\n",
      "loaded: 5000\n",
      "loaded: 5500\n",
      "loaded: 6000\n",
      "loaded: 6500\n",
      "loaded: 7000\n",
      "loaded: 7500\n",
      "loaded: 8000\n",
      "loaded: 8500\n",
      "loaded: 9000\n",
      "loaded: 9500\n",
      "loaded: 10000\n",
      "loaded: 10500\n",
      "loaded: 11000\n",
      "loaded: 11500\n",
      "loaded: 12000\n",
      "loaded: 12500\n"
     ]
    }
   ],
   "source": [
    "(trainX, trainY) = load_data(train_data)\n",
    "(testX, testY) = load_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39209, 32, 32, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = trainX / 255.0\n",
    "test_X = testX / 255.0\n",
    "\n",
    "num_labels = len(np.unique(trainY))\n",
    "train_Y = to_categorical(trainY, num_labels)\n",
    "test_Y = to_categorical(trainY, num_labels)\n",
    "\n",
    "class_totals = train_Y.sum(axis=0)\n",
    "class_weight = class_totals.max() / class_totals\n",
    "\n",
    "train_X[100].shape\n",
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoadSignClassifier:\n",
    "    def createCNN(width, height, depth, classes):\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        \n",
    "        \n",
    "        #1st convolution layer\n",
    "        model.add(Conv2D(8, (5, 5), input_shape=inputShape, activation=\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv2D(16, (3, 3), activation=\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(16, (3, 3), activation=\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "        model.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        #fully connected layer\n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(128, activation=\"relu\"))\n",
    "        \n",
    "        \n",
    "        #output\n",
    "        model.add(Dense(classes, activation=\"softmax\"))\n",
    "        return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug = ImageDataGenerator(\n",
    "rotation_range=10,\n",
    "zoom_range=0.15,\n",
    "width_shift_range=0.1,\n",
    "height_shift_range=0.1,\n",
    "shear_range=0.15,\n",
    "horizontal_flip=False,\n",
    "vertical_flip=False)\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "pred_model = ModelCheckpoint('classifier.hdf5', save_best_only=True, monitor='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "613/613 [==============================] - 76s 124ms/step - loss: 2.1707 - accuracy: 0.3871 - val_loss: 9.1267 - val_accuracy: 0.0409\n",
      "Epoch 2/10\n",
      "613/613 [==============================] - 78s 127ms/step - loss: 0.9845 - accuracy: 0.6860 - val_loss: 11.5497 - val_accuracy: 0.0390\n",
      "Epoch 3/10\n",
      "613/613 [==============================] - 73s 119ms/step - loss: 0.6296 - accuracy: 0.7965 - val_loss: 12.5266 - val_accuracy: 0.0394\n",
      "Epoch 4/10\n",
      "613/613 [==============================] - 59s 96ms/step - loss: 0.4756 - accuracy: 0.8476 - val_loss: 13.0587 - val_accuracy: 0.0394\n",
      "Epoch 5/10\n",
      "613/613 [==============================] - 66s 108ms/step - loss: 0.3860 - accuracy: 0.8761 - val_loss: 13.6012 - val_accuracy: 0.0389\n",
      "Epoch 6/10\n",
      "613/613 [==============================] - 80s 130ms/step - loss: 0.3272 - accuracy: 0.8936 - val_loss: 13.7279 - val_accuracy: 0.0391\n",
      "Epoch 7/10\n",
      "613/613 [==============================] - 83s 135ms/step - loss: 0.2975 - accuracy: 0.9044 - val_loss: 13.6767 - val_accuracy: 0.0385\n",
      "Epoch 8/10\n",
      "613/613 [==============================] - 86s 141ms/step - loss: 0.2595 - accuracy: 0.9168 - val_loss: 13.9537 - val_accuracy: 0.0387\n",
      "Epoch 9/10\n",
      "613/613 [==============================] - 124s 203ms/step - loss: 0.2337 - accuracy: 0.9241 - val_loss: 14.0637 - val_accuracy: 0.0392\n",
      "Epoch 10/10\n",
      "613/613 [==============================] - 84s 137ms/step - loss: 0.2160 - accuracy: 0.9291 - val_loss: 14.1354 - val_accuracy: 0.0394\n"
     ]
    }
   ],
   "source": [
    "model = RoadSignClassifier.createCNN(width=img_size, height=img_size, depth=3, classes=43)\n",
    "optimizer = Adam(lr=learning_rate, decay=learning_rate / (epochs))\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])    \n",
    "\n",
    "\n",
    "network = model.fit_generator(\n",
    "    data_aug.flow(train_X, train_Y, batch_size=batch_size), \n",
    "    epochs=epochs,\n",
    "    validation_data=(test_X, test_Y),\n",
    "    class_weight=class_weight,\n",
    "    verbose=1,\n",
    "    callbacks=[pred_model])\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_save = load_model(\"classifier.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):    \n",
    "    R, G, B = cv2.split(image)\n",
    "\n",
    "    img_r = cv2.equalizeHist(R)\n",
    "    img_g = cv2.equalizeHist(G)\n",
    "    img_b = cv2.equalizeHist(B)\n",
    "\n",
    "    new_image = cv2.merge((img_r, img_g, img_b))\n",
    "    \n",
    "    img = new_image/255\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 32\n",
    "image = testX[685]\n",
    "img = np.asarray(image)\n",
    "img = cv2.resize(img, (img_size, img_size), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25d15094b48>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img, cmap = ('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = preprocess(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.reshape(1, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted sign: [2]\n"
     ]
    }
   ],
   "source": [
    "print(\"predicted sign: \"+ str(model_save.predict_classes(img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
